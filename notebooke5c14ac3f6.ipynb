{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12114200,"sourceType":"datasetVersion","datasetId":7627295}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-10T03:29:53.810176Z","iopub.execute_input":"2025-06-10T03:29:53.810497Z","iopub.status.idle":"2025-06-10T03:29:56.111416Z","shell.execute_reply.started":"2025-06-10T03:29:53.810466Z","shell.execute_reply":"2025-06-10T03:29:56.110467Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import classification_report","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T03:30:00.995358Z","iopub.execute_input":"2025-06-10T03:30:00.995644Z","iopub.status.idle":"2025-06-10T03:30:02.044176Z","shell.execute_reply.started":"2025-06-10T03:30:00.995621Z","shell.execute_reply":"2025-06-10T03:30:02.043206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Kaggle 데이터셋 경로\ninput_dir = '/kaggle/input/open123123121212'\n\n# CSV 불러오기\ntrain = pd.read_csv(f'{input_dir}/train.csv')\ntest = pd.read_csv(f'{input_dir}/test.csv')\nsubmission = pd.read_csv(f'{input_dir}/sample_submission.csv')\n\n# 데이터 확인\nprint(\"train:\", train.shape)\nprint(\"test:\", test.shape)\nprint(\"submission:\", submission.shape)\n\n# 상위 5개 살펴보기\ndisplay(train_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T04:20:20.198865Z","iopub.execute_input":"2025-06-10T04:20:20.199731Z","iopub.status.idle":"2025-06-10T04:20:20.301247Z","shell.execute_reply.started":"2025-06-10T04:20:20.199694Z","shell.execute_reply":"2025-06-10T04:20:20.300290Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2) X, y, test 정의\nX = train.drop(['ID','attack_type'], axis=1)\ny = train['attack_type']\ntest = test.drop(['ID'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T04:20:25.922226Z","iopub.execute_input":"2025-06-10T04:20:25.922532Z","iopub.status.idle":"2025-06-10T04:20:25.931074Z","shell.execute_reply.started":"2025-06-10T04:20:25.922511Z","shell.execute_reply":"2025-06-10T04:20:25.930117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.experimental import enable_iterative_imputer  # noqa: F401\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\n\nfrom lightgbm import LGBMClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T04:20:49.764804Z","iopub.execute_input":"2025-06-10T04:20:49.765586Z","iopub.status.idle":"2025-06-10T04:20:56.148344Z","shell.execute_reply.started":"2025-06-10T04:20:49.765549Z","shell.execute_reply":"2025-06-10T04:20:56.147430Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3) 헬퍼 함수 정의\ndef port_group(port):\n    if port <= 1023:\n        return 'well_known'\n    if port <= 49151:\n        return 'registered'\n    return 'dynamic'\n\ndef make_features(df):\n    # 포트 그룹화\n    df['port_src_grp'] = df['port_src'].apply(port_group)\n    df['port_dst_grp'] = df['port_dst'].apply(port_group)\n    # 서브넷 추출 (첫 두 옥텟)\n    df['subnet_src'] = (\n        df['ip_src']\n          .fillna('0.0.0.0').astype(str)\n          .str.split('.', n=3).str[:2].str.join('.')\n    )\n    df['subnet_dst'] = (\n        df['ip_dst']\n          .fillna('0.0.0.0').astype(str)\n          .str.split('.', n=3).str[:2].str.join('.')\n    )\n    # 파생 변수\n    df['pkt_count_total']    = df['pkt_count_fwd'] + df['pkt_count_bwd']\n    df['avg_pkt_size']       = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['pkt_count_total'] + 1e-6)\n    df['byte_ratio_fwd']     = df['rate_fwd_bytes'] / ((df['rate_fwd_bytes'] + df['rate_bwd_bytes']) + 1e-6)\n    df['iat_pkt_rate_ratio'] = df['iat_avg_packets'] / ((df['rate_fwd_pkts'] + df['rate_bwd_pkts']) + 1e-6)\n    df['tcp_ctrl_ratio']     = (df['tcp_syn_count'] + df['tcp_psh_count'] + df['tcp_rst_count']) / (df['pkt_count_total'] + 1e-6)\n    df['throughput']         = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['duration'] + 1e-6)\n    df['tcp_win_ratio']      = df['tcp_win_fwd_init'] / (df['tcp_win_bwd_init'] + 1e-6)\n\n# 4) 파생 변수 적용\nfor df_ in (X, test):\n    make_features(df_)\n\n# 5) 피처 리스트 정의\nnumeric_cols = [\n    'port_src','port_dst','duration','pkt_count_fwd','pkt_count_bwd',\n    'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes','rate_bwd_bytes',\n    'payload_fwd_mean','payload_bwd_mean','tcp_win_fwd_init','tcp_win_bwd_init',\n    'tcp_syn_count','tcp_psh_count','tcp_rst_count','iat_avg_packets',\n    'pkt_count_total','avg_pkt_size','byte_ratio_fwd','iat_pkt_rate_ratio',\n    'tcp_ctrl_ratio','throughput','tcp_win_ratio'\n]\ncategorical_features = ['protocol','port_src_grp','port_dst_grp','subnet_src','subnet_dst']\n\n# 6) 파이프라인 구성\nnumeric_transformer = Pipeline([\n    ('imputer', IterativeImputer(random_state=42, max_iter=10, sample_posterior=True)),\n    ('scaler',  StandardScaler())\n])\ncategorical_transformer = Pipeline([\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n])\npreprocessor = ColumnTransformer([\n    ('num', numeric_transformer,   numeric_cols),\n    ('cat', categorical_transformer, categorical_features)\n])\npipeline = Pipeline([\n    ('preproc', preprocessor),\n    ('clf',     LGBMClassifier(random_state=42, n_estimators=200))\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T04:21:05.409732Z","iopub.execute_input":"2025-06-10T04:21:05.410648Z","iopub.status.idle":"2025-06-10T04:21:05.652341Z","shell.execute_reply.started":"2025-06-10T04:21:05.410613Z","shell.execute_reply":"2025-06-10T04:21:05.651287Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 7) 교차 검증\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nscores = cross_val_score(pipeline, X, y, cv=cv, scoring='f1_macro')\nprint(f'5-fold Macro F1 Score: {np.mean(scores):.4f}')\n\n# 8) 최종 학습 & 예측\npipeline.fit(X, y)\npred = pipeline.predict(test)\n\n# 9) 제출 파일 생성\nsubmission['attack_type'] = pred\nsubmission.to_csv('final_submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T04:21:18.959389Z","iopub.execute_input":"2025-06-10T04:21:18.959679Z","iopub.status.idle":"2025-06-10T04:22:33.906220Z","shell.execute_reply.started":"2025-06-10T04:21:18.959657Z","shell.execute_reply":"2025-06-10T04:22:33.905303Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# attack_type별 샘플 수 확인\nprint(y.value_counts())\ny.value_counts(normalize=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T04:30:30.864922Z","iopub.execute_input":"2025-06-10T04:30:30.865295Z","iopub.status.idle":"2025-06-10T04:30:30.881462Z","shell.execute_reply.started":"2025-06-10T04:30:30.865270Z","shell.execute_reply":"2025-06-10T04:30:30.880582Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ny.value_counts().plot.bar()\nplt.title(\"Class Distribution\")\nplt.ylabel(\"Count\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T04:30:48.336630Z","iopub.execute_input":"2025-06-10T04:30:48.336966Z","iopub.status.idle":"2025-06-10T04:30:48.712952Z","shell.execute_reply.started":"2025-06-10T04:30:48.336940Z","shell.execute_reply":"2025-06-10T04:30:48.712008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 예: cross_val_score로 train, val 나눠 점수 확인\nfrom sklearn.model_selection import cross_validate\nscores = cross_validate(pipeline, X, y, cv=5,\n                        return_train_score=True,\n                        scoring='f1_macro')\nprint(\"Train F1:\", scores['train_score'].mean())\nprint(\"Val   F1:\", scores['test_score'].mean()) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T04:31:06.772952Z","iopub.execute_input":"2025-06-10T04:31:06.773298Z","iopub.status.idle":"2025-06-10T04:32:10.443916Z","shell.execute_reply.started":"2025-06-10T04:31:06.773273Z","shell.execute_reply":"2025-06-10T04:32:10.442980Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --upgrade imbalanced-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T04:43:37.774459Z","iopub.execute_input":"2025-06-10T04:43:37.774755Z","iopub.status.idle":"2025-06-10T04:43:47.083592Z","shell.execute_reply.started":"2025-06-10T04:43:37.774736Z","shell.execute_reply":"2025-06-10T04:43:47.082548Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"smote 적용 및 xgboost 모델 변경 ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.experimental import enable_iterative_imputer  # noqa: F401\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nfrom sklearn.utils import resample\nfrom xgboost import XGBClassifier\n\n# -----------------------------------------------------------------------------\n# 1) Kaggle 노트북 환경에서 데이터 로드\n# -----------------------------------------------------------------------------\ninput_dir  = '/kaggle/input/open123123121212'\ntrain      = pd.read_csv(f'{input_dir}/train.csv')\ntest       = pd.read_csv(f'{input_dir}/test.csv')\nsubmission = pd.read_csv(f'{input_dir}/sample_submission.csv')\n\nprint(\"train:\", train.shape)\nprint(\"test: \", test.shape)\nprint(\"submission:\", submission.shape)\ndisplay(train.head())\n\n# -----------------------------------------------------------------------------\n# 2) X, y, test 준비 및 레이블 인코딩\n# -----------------------------------------------------------------------------\nX_raw    = train.drop(['ID','attack_type'], axis=1)\ny_raw    = train['attack_type']\ntest_raw = test.drop(['ID'], axis=1)\n\nle = LabelEncoder()\ny  = le.fit_transform(y_raw)  # 문자열 레이블 → 0,1,2...\n\n# -----------------------------------------------------------------------------\n# 3) 헬퍼 함수 & 파생 변수 생성\n# -----------------------------------------------------------------------------\ndef port_group(port):\n    if port <= 1023:\n        return 'well_known'\n    elif port <= 49151:\n        return 'registered'\n    else:\n        return 'dynamic'\n\ndef make_features(df):\n    # 포트 구간화\n    df['port_src_grp'] = df['port_src'].apply(port_group)\n    df['port_dst_grp'] = df['port_dst'].apply(port_group)\n    # 서브넷(첫 두 옥텟)\n    df['subnet_src'] = (\n        df['ip_src'].fillna('0.0.0.0').astype(str)\n          .str.split('.', n=3).str[:2].str.join('.')\n    )\n    df['subnet_dst'] = (\n        df['ip_dst'].fillna('0.0.0.0').astype(str)\n          .str.split('.', n=3).str[:2].str.join('.')\n    )\n    # 파생 변수\n    df['pkt_count_total']    = df['pkt_count_fwd'] + df['pkt_count_bwd']\n    df['avg_pkt_size']       = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['pkt_count_total'] + 1e-6)\n    df['byte_ratio_fwd']     = df['rate_fwd_bytes'] / (df['rate_fwd_bytes'] + df['rate_bwd_bytes'] + 1e-6)\n    df['iat_pkt_rate_ratio'] = df['iat_avg_packets'] / (df['rate_fwd_pkts'] + df['rate_bwd_pkts'] + 1e-6)\n    df['tcp_ctrl_ratio']     = (df['tcp_syn_count'] + df['tcp_psh_count'] + df['tcp_rst_count']) / (df['pkt_count_total'] + 1e-6)\n    df['throughput']         = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['duration'] + 1e-6)\n    df['tcp_win_ratio']      = df['tcp_win_fwd_init'] / (df['tcp_win_bwd_init'] + 1e-6)\n\nfor df_ in (X_raw, test_raw):\n    make_features(df_)\n\n# -----------------------------------------------------------------------------\n# 4) 전처리 파이프라인 설정 (희소 행렬 유지)\n# -----------------------------------------------------------------------------\nnumeric_cols = [\n    'port_src','port_dst','duration','pkt_count_fwd','pkt_count_bwd',\n    'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes','rate_bwd_bytes',\n    'payload_fwd_mean','payload_bwd_mean','tcp_win_fwd_init','tcp_win_bwd_init',\n    'tcp_syn_count','tcp_psh_count','tcp_rst_count','iat_avg_packets',\n    'pkt_count_total','avg_pkt_size','byte_ratio_fwd','iat_pkt_rate_ratio',\n    'tcp_ctrl_ratio','throughput','tcp_win_ratio'\n]\ncategorical_features = ['protocol','port_src_grp','port_dst_grp','subnet_src','subnet_dst']\n\nnumeric_transformer = Pipeline([\n    ('imputer', IterativeImputer(random_state=42, max_iter=10, sample_posterior=True)),\n    ('scaler',  StandardScaler(with_mean=False))  # 희소 행렬 호환\n])\ncategorical_transformer = Pipeline([\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))\n])\npreprocessor = ColumnTransformer([\n    ('num', numeric_transformer,   numeric_cols),\n    ('cat', categorical_transformer, categorical_features)\n], sparse_threshold=1.0)\n\n# -----------------------------------------------------------------------------\n# 5) 전처리 실행\n# -----------------------------------------------------------------------------\nX_proc    = preprocessor.fit_transform(X_raw)\ntest_proc = preprocessor.transform(test_raw)\n\n# -----------------------------------------------------------------------------\n# 6) 수동 오버샘플링 함수\n# -----------------------------------------------------------------------------\ndef oversample(X_arr, y_arr):\n    classes, counts = np.unique(y_arr, return_counts=True)\n    max_count = counts.max()\n    X_res_list, y_res_list = [], []\n    for cls in classes:\n        idx     = np.where(y_arr == cls)[0]\n        X_cls   = X_arr[idx]\n        y_cls   = y_arr[idx]\n        # 희소행렬을 밀집 배열로 변환 후 복제\n        X_dense = X_cls.toarray() if hasattr(X_cls, \"toarray\") else X_cls\n        X_up, y_up = resample(\n            X_dense, y_cls,\n            replace=True,\n            n_samples=max_count,\n            random_state=42\n        )\n        X_res_list.append(X_up)\n        y_res_list.append(y_up)\n    return np.vstack(X_res_list), np.concatenate(y_res_list)\n\n# -----------------------------------------------------------------------------\n# 7) 모델 정의\n# -----------------------------------------------------------------------------\nclf = XGBClassifier(\n    n_estimators=500,\n    learning_rate=0.1,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    use_label_encoder=False,\n    eval_metric='mlogloss',\n    random_state=42\n)\n\n# -----------------------------------------------------------------------------\n# 8) 교차검증 (Manual oversampling + 평가)\n# -----------------------------------------------------------------------------\ncv        = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nf1_scores = []\nfor tr_idx, va_idx in cv.split(X_proc, y):\n    X_tr, X_va = X_proc[tr_idx], X_proc[va_idx]\n    y_tr, y_va = y[tr_idx], y[va_idx]\n    X_tr_res, y_tr_res = oversample(X_tr, y_tr)\n    clf.fit(X_tr_res, y_tr_res)\n    y_pred = clf.predict(X_va)\n    f1_scores.append(f1_score(y_va, y_pred, average='macro'))\n\nprint(\"5-fold Macro F1 scores:\", np.round(f1_scores, 4))\nprint(\"Mean Macro F1 score:\", np.round(np.mean(f1_scores), 4))\n\n# -----------------------------------------------------------------------------\n# 9) 최종 학습 및 예측\n# -----------------------------------------------------------------------------\nX_res_full, y_res_full = oversample(X_proc, y)\nclf.fit(X_res_full, y_res_full)\npred_int    = clf.predict(test_proc)\npred_labels = le.inverse_transform(pred_int)\n\n# -----------------------------------------------------------------------------\n# 10) 제출 파일 생성\n# -----------------------------------------------------------------------------\nsubmission['attack_type'] = pred_labels\nsubmission.to_csv('final_submission.csv', index=False)\nprint(\"완료: final_submission.csv 생성되었습니다.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:00:00.060872Z","iopub.execute_input":"2025-06-10T10:00:00.061157Z","iopub.status.idle":"2025-06-10T10:40:29.604611Z","shell.execute_reply.started":"2025-06-10T10:00:00.061132Z","shell.execute_reply":"2025-06-10T10:40:29.603446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\nfrom sklearn.metrics import make_scorer, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import StackingClassifier\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n# 1) Load data\nINPUT = '/kaggle/input/open123123121212'\ntrain      = pd.read_csv(f'{INPUT}/train.csv')\ntest       = pd.read_csv(f'{INPUT}/test.csv')\nsubmission = pd.read_csv(f'{INPUT}/sample_submission.csv')\n\n# 2) Prepare X, y and encode labels\nX       = train.drop(['ID', 'attack_type'], axis=1)\ny_raw   = train['attack_type']\nle      = LabelEncoder()\ny       = le.fit_transform(y_raw)\n\n# 3) Feature engineering\ndef port_group(p):\n    if p <= 1023:\n        return 'well_known'\n    elif p <= 49151:\n        return 'registered'\n    else:\n        return 'dynamic'\n\ndef make_features(df):\n    df['port_src_grp'] = df['port_src'].apply(port_group)\n    df['port_dst_grp'] = df['port_dst'].apply(port_group)\n    df['subnet_src'] = (\n        df['ip_src'].fillna('0.0.0.0').astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['subnet_dst'] = (\n        df['ip_dst'].fillna('0.0.0.0').astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['pkt_count_total']    = df['pkt_count_fwd'] + df['pkt_count_bwd']\n    df['avg_pkt_size']       = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['pkt_count_total'] + 1e-6)\n    df['byte_ratio_fwd']     = df['rate_fwd_bytes'] / (df['rate_fwd_bytes'] + df['rate_bwd_bytes'] + 1e-6)\n    df['iat_pkt_rate_ratio'] = df['iat_avg_packets'] / (df['rate_fwd_pkts'] + df['rate_bwd_pkts'] + 1e-6)\n    df['tcp_ctrl_ratio']     = (df['tcp_syn_count'] + df['tcp_psh_count'] + df['tcp_rst_count']) / (df['pkt_count_total'] + 1e-6)\n    df['throughput']         = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['duration'] + 1e-6)\n    df['tcp_win_ratio']      = df['tcp_win_fwd_init'] / (df['tcp_win_bwd_init'] + 1e-6)\n    for c in ['duration','pkt_count_fwd','pkt_count_bwd','rate_fwd_pkts','rate_bwd_pkts',\n              'rate_fwd_bytes','rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n              'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']:\n        df[f'{c}_log1p'] = np.log1p(df[c].fillna(0))\n    return df\n\nX    = make_features(X.copy())\ntest = make_features(test.copy())\n\n# 4) Preprocessing pipeline\nnumeric_cols = [\n    'port_src','port_dst','duration','pkt_count_fwd','pkt_count_bwd',\n    'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes','rate_bwd_bytes',\n    'payload_fwd_mean','payload_bwd_mean','tcp_win_fwd_init','tcp_win_bwd_init',\n    'tcp_syn_count','tcp_psh_count','tcp_rst_count','iat_avg_packets',\n    'pkt_count_total','avg_pkt_size','byte_ratio_fwd','iat_pkt_rate_ratio',\n    'tcp_ctrl_ratio','throughput','tcp_win_ratio'\n] + [f'{c}_log1p' for c in ['duration','pkt_count_fwd','pkt_count_bwd',\n                            'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes',\n                            'rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n                            'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']]\ncategorical_features = ['protocol','port_src_grp','port_dst_grp','subnet_src','subnet_dst']\n\nnum_pipe = Pipeline([\n    ('imputer', IterativeImputer(random_state=42, max_iter=10, sample_posterior=True)),\n    ('scaler',  StandardScaler(with_mean=False))\n])\ncat_pipe = Pipeline([\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))\n])\npreproc = ColumnTransformer([\n    ('num', num_pipe, numeric_cols),\n    ('cat', cat_pipe, categorical_features)\n], sparse_threshold=1.0)\n\n# 5) Stacking ensemble with early stopping\nestimators = [\n    ('xgb', XGBClassifier(\n        n_estimators=1000, learning_rate=0.05, max_depth=6,\n        subsample=0.8, colsample_bytree=0.8,\n        use_label_encoder=False, eval_metric='mlogloss',\n        early_stopping_rounds=50, random_state=42, n_jobs=4\n    )),\n    ('lgb', LGBMClassifier(\n        n_estimators=1000, learning_rate=0.05, num_leaves=50,\n        subsample=0.8, colsample_bytree=0.8,\n        class_weight='balanced', random_state=42, n_jobs=4\n    )),\n    ('cat', CatBoostClassifier(\n        iterations=1000, learning_rate=0.05, depth=6,\n        auto_class_weights='Balanced',\n        early_stopping_rounds=50, random_seed=42,\n        verbose=0\n    ))\n]\nstack = StackingClassifier(\n    estimators=estimators,\n    final_estimator=LogisticRegression(max_iter=1000),\n    cv=5,\n    passthrough=True,\n    n_jobs=-1\n)\n\npipeline = Pipeline([\n    ('pre',   preproc),\n    ('stack', stack)\n])\n\n# 6) Hyperparameter search\nparam_dist = {\n    'stack__xgb__learning_rate': [0.01, 0.05, 0.1],\n    'stack__xgb__max_depth':      [4, 6, 8],\n    'stack__lgb__num_leaves':     [31, 50, 100],\n    'stack__cat__depth':          [4, 6, 8],\n    'stack__final_estimator__C':  [0.01, 0.1, 1, 10],\n}\n\nsearch = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=20,\n    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n    scoring=make_scorer(f1_score, average='macro'),\n    n_jobs=-1,\n    random_state=42,\n    verbose=2\n)\n\n# 7) Fit and tune\nsearch.fit(X, y)\nprint(\"Best CV Macro F1:\", search.best_score_)\nprint(\"Best Params:\", search.best_params_)\n\n# 8) Final predict and submit\nbest = search.best_estimator_\npred_int   = best.predict(test)\npred_label = le.inverse_transform(pred_int)\n\nsubmission['attack_type'] = pred_label\nsubmission.to_csv('stacking_tuned_submission.csv', index=False)\nprint(\"Completed: stacking_tuned_submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T03:17:58.786335Z","iopub.execute_input":"2025-06-11T03:17:58.786570Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\nfrom sklearn.metrics import make_scorer, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import StackingClassifier\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n# 1) 데이터 로드\nINPUT = '/kaggle/input/open123123121212'\ntrain      = pd.read_csv(f'{INPUT}/train.csv')\ntest       = pd.read_csv(f'{INPUT}/test.csv')\nsubmission = pd.read_csv(f'{INPUT}/sample_submission.csv')\n\n# 2) X, y 준비 및 레이블 인코딩\nX       = train.drop(['ID', 'attack_type'], axis=1)\ny_raw   = train['attack_type']\nle      = LabelEncoder()\ny       = le.fit_transform(y_raw)\n\n# 3) 피처 엔지니어링\ndef port_group(p):\n    if p <= 1023:       return 'well_known'\n    elif p <= 49151:    return 'registered'\n    else:               return 'dynamic'\n\ndef make_features(df):\n    df['port_src_grp'] = df['port_src'].apply(port_group)\n    df['port_dst_grp'] = df['port_dst'].apply(port_group)\n    df['subnet_src'] = (\n        df['ip_src'].fillna('0.0.0.0')\n          .astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['subnet_dst'] = (\n        df['ip_dst'].fillna('0.0.0.0')\n          .astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['pkt_count_total']    = df['pkt_count_fwd'] + df['pkt_count_bwd']\n    df['avg_pkt_size']       = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['pkt_count_total'] + 1e-6)\n    df['byte_ratio_fwd']     = df['rate_fwd_bytes'] / (df['rate_fwd_bytes'] + df['rate_bwd_bytes'] + 1e-6)\n    df['iat_pkt_rate_ratio'] = df['iat_avg_packets'] / (df['rate_fwd_pkts'] + df['rate_bwd_pkts'] + 1e-6)\n    df['tcp_ctrl_ratio']     = (df['tcp_syn_count'] + df['tcp_psh_count'] + df['tcp_rst_count']) / (df['pkt_count_total'] + 1e-6)\n    df['throughput']         = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['duration'] + 1e-6)\n    df['tcp_win_ratio']      = df['tcp_win_fwd_init'] / (df['tcp_win_bwd_init'] + 1e-6)\n    for c in ['duration','pkt_count_fwd','pkt_count_bwd','rate_fwd_pkts','rate_bwd_pkts',\n              'rate_fwd_bytes','rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n              'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']:\n        df[f'{c}_log1p'] = np.log1p(df[c].fillna(0))\n    return df\n\nX    = make_features(X.copy())\ntest = make_features(test.copy())\n\n# 4) 전처리 파이프라인\nnumeric_cols = [\n    'port_src','port_dst','duration','pkt_count_fwd','pkt_count_bwd',\n    'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes','rate_bwd_bytes',\n    'payload_fwd_mean','payload_bwd_mean','tcp_win_fwd_init','tcp_win_bwd_init',\n    'tcp_syn_count','tcp_psh_count','tcp_rst_count','iat_avg_packets',\n    'pkt_count_total','avg_pkt_size','byte_ratio_fwd','iat_pkt_rate_ratio',\n    'tcp_ctrl_ratio','throughput','tcp_win_ratio'\n] + [f'{c}_log1p' for c in ['duration','pkt_count_fwd','pkt_count_bwd',\n                            'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes',\n                            'rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n                            'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']]\ncategorical_features = ['protocol','port_src_grp','port_dst_grp','subnet_src','subnet_dst']\n\nnum_pipe = Pipeline([\n    ('imputer', IterativeImputer(random_state=42, max_iter=10, sample_posterior=True)),\n    ('scaler',  StandardScaler(with_mean=False))\n])\ncat_pipe = Pipeline([\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))\n])\npreproc = ColumnTransformer([\n    ('num', num_pipe, numeric_cols),\n    ('cat', cat_pipe, categorical_features)\n], sparse_threshold=1.0)\n\n# 5) Stacking ensemble with early stopping\nestimators = [\n    ('xgb', XGBClassifier(\n        n_estimators=1000, learning_rate=0.05, max_depth=6,\n        subsample=0.8, colsample_bytree=0.8,\n        use_label_encoder=False, eval_metric='mlogloss',\n        early_stopping_rounds=50, random_state=42, n_jobs=4\n    )),\n    ('lgb', LGBMClassifier(\n        n_estimators=1000, learning_rate=0.05, num_leaves=50,\n        subsample=0.8, colsample_bytree=0.8,\n        class_weight='balanced', random_state=42, n_jobs=4\n    )),\n    ('cat', CatBoostClassifier(\n        iterations=1000, learning_rate=0.05, depth=6,\n        auto_class_weights='Balanced',\n        early_stopping_rounds=50, random_seed=42,\n        verbose=0\n    ))\n]\nstack = StackingClassifier(\n    estimators=estimators,\n    final_estimator=LogisticRegression(max_iter=1000),\n    cv=5,\n    passthrough=True,\n    n_jobs=-1\n)\npipeline = Pipeline([\n    ('pre',   preproc),\n    ('stack', stack)\n])\n\n# 6) Hyperparameter search\nparam_dist = {\n    'stack__xgb__learning_rate': [0.01, 0.05, 0.1],\n    'stack__xgb__max_depth':      [4, 6, 8],\n    'stack__lgb__num_leaves':     [31, 50, 100],\n    'stack__cat__depth':          [4, 6, 8],\n    'stack__final_estimator__C':  [0.01, 0.1, 1, 10],\n}\nsearch = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=20,\n    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n    scoring=make_scorer(f1_score, average='macro'),\n    n_jobs=-1,\n    random_state=42,\n    verbose=2\n)\n\n# 7) Fit and tune\nsearch.fit(X, y)\nprint(\"Best CV Macro F1:\", search.best_score_)\nprint(\"Best Params:\", search.best_params_)\n\n# 8) Final predict and save to Kaggle working dir\nbest = search.best_estimator_\npred_int   = best.predict(test)\npred_label = le.inverse_transform(pred_int)\nsubmission['attack_type'] = pred_label\nsubmission.to_csv('/kaggle/working/stacking_tuned_submission.csv', index=False)\nprint(\"Completed: /kaggle/working/stacking_tuned_submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T06:26:01.865034Z","iopub.execute_input":"2025-06-11T06:26:01.865349Z","iopub.status.idle":"2025-06-11T06:48:17.195284Z","shell.execute_reply.started":"2025-06-11T06:26:01.865324Z","shell.execute_reply":"2025-06-11T06:48:17.190267Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\nfrom sklearn.metrics import make_scorer, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import StackingClassifier\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n# 1) 데이터 로드\nINPUT = '/kaggle/input/open123123121212'\ntrain      = pd.read_csv(f'{INPUT}/train.csv')\ntest       = pd.read_csv(f'{INPUT}/test.csv')\nsubmission = pd.read_csv(f'{INPUT}/sample_submission.csv')\n\n# 2) X, y 준비 및 레이블 인코딩\nX       = train.drop(['ID', 'attack_type'], axis=1)\ny_raw   = train['attack_type']\nle      = LabelEncoder()\ny       = le.fit_transform(y_raw)\n\n# 3) 피처 엔지니어링\ndef port_group(p):\n    if p <= 1023:       return 'well_known'\n    elif p <= 49151:    return 'registered'\n    else:               return 'dynamic'\n\ndef make_features(df):\n    df['port_src_grp'] = df['port_src'].apply(port_group)\n    df['port_dst_grp'] = df['port_dst'].apply(port_group)\n    df['subnet_src'] = (\n        df['ip_src'].fillna('0.0.0.0')\n          .astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['subnet_dst'] = (\n        df['ip_dst'].fillna('0.0.0.0')\n          .astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['pkt_count_total']    = df['pkt_count_fwd'] + df['pkt_count_bwd']\n    df['avg_pkt_size']       = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['pkt_count_total'] + 1e-6)\n    df['byte_ratio_fwd']     = df['rate_fwd_bytes'] / (df['rate_fwd_bytes'] + df['rate_bwd_bytes'] + 1e-6)\n    df['iat_pkt_rate_ratio'] = df['iat_avg_packets'] / (df['rate_fwd_pkts'] + df['rate_bwd_pkts'] + 1e-6)\n    df['tcp_ctrl_ratio']     = (df['tcp_syn_count'] + df['tcp_psh_count'] + df['tcp_rst_count']) / (df['pkt_count_total'] + 1e-6)\n    df['throughput']         = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['duration'] + 1e-6)\n    df['tcp_win_ratio']      = df['tcp_win_fwd_init'] / (df['tcp_win_bwd_init'] + 1e-6)\n    for c in ['duration','pkt_count_fwd','pkt_count_bwd','rate_fwd_pkts','rate_bwd_pkts',\n              'rate_fwd_bytes','rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n              'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']:\n        df[f'{c}_log1p'] = np.log1p(df[c].fillna(0))\n    return df\n\nX    = make_features(X.copy())\ntest = make_features(test.copy())\n\n# 4) 전처리 파이프라인\nnumeric_cols = [\n    'port_src','port_dst','duration','pkt_count_fwd','pkt_count_bwd',\n    'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes','rate_bwd_bytes',\n    'payload_fwd_mean','payload_bwd_mean','tcp_win_fwd_init','tcp_win_bwd_init',\n    'tcp_syn_count','tcp_psh_count','tcp_rst_count','iat_avg_packets',\n    'pkt_count_total','avg_pkt_size','byte_ratio_fwd','iat_pkt_rate_ratio',\n    'tcp_ctrl_ratio','throughput','tcp_win_ratio'\n] + [f'{c}_log1p' for c in ['duration','pkt_count_fwd','pkt_count_bwd',\n                            'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes',\n                            'rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n                            'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']]\ncategorical_features = ['protocol','port_src_grp','port_dst_grp','subnet_src','subnet_dst']\n\nnum_pipe = Pipeline([\n    ('imputer', IterativeImputer(random_state=42, max_iter=10, sample_posterior=True)),\n    ('scaler',  StandardScaler(with_mean=False))\n])\ncat_pipe = Pipeline([\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))\n])\npreproc = ColumnTransformer([\n    ('num', num_pipe, numeric_cols),\n    ('cat', cat_pipe, categorical_features)\n], sparse_threshold=1.0)\n\n# 5) Stacking ensemble with early stopping\nestimators = [\n    ('xgb', XGBClassifier(\n        n_estimators=1000, learning_rate=0.05, max_depth=6,\n        subsample=0.8, colsample_bytree=0.8,\n        use_label_encoder=False, eval_metric='mlogloss',\n        early_stopping_rounds=50, random_state=42, n_jobs=4\n    )),\n    ('lgb', LGBMClassifier(\n        n_estimators=1000, learning_rate=0.05, num_leaves=50,\n        subsample=0.8, colsample_bytree=0.8,\n        class_weight='balanced', random_state=42, n_jobs=4\n    )),\n    ('cat', CatBoostClassifier(\n        iterations=1000, learning_rate=0.05, depth=6,\n        auto_class_weights='Balanced',\n        early_stopping_rounds=50, random_seed=42,\n        verbose=0\n    ))\n]\nstack = StackingClassifier(\n    estimators=estimators,\n    final_estimator=LogisticRegression(max_iter=1000),\n    cv=5,\n    passthrough=True,\n    n_jobs=-1\n)\npipeline = Pipeline([\n    ('pre',   preproc),\n    ('stack', stack)\n])\n\n# 6) Hyperparameter search\nparam_dist = {\n    'stack__xgb__learning_rate': [0.01, 0.05, 0.1],\n    'stack__xgb__max_depth':      [4, 6, 8],\n    'stack__lgb__num_leaves':     [31, 50, 100],\n    'stack__cat__depth':          [4, 6, 8],\n    'stack__final_estimator__C':  [0.01, 0.1, 1, 10],\n}\nsearch = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=20,\n    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n    scoring=make_scorer(f1_score, average='macro'),\n    n_jobs=-1,\n    random_state=42,\n    verbose=2\n)\n\n# 7) Fit and tune\nsearch.fit(X, y)\nprint(\"Best CV Macro F1:\", search.best_score_)\nprint(\"Best Params:\", search.best_params_)\n\n# 8) Final predict and save to Kaggle working dir\nbest = search.best_estimator_\npred_int   = best.predict(test)\npred_label = le.inverse_transform(pred_int)\nsubmission['attack_type'] = pred_label\nsubmission.to_csv('/kaggle/working/stacking_tuned_submission.csv', index=False)\nprint(\"Completed: /kaggle/working/stacking_tuned_submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T14:21:56.029911Z","iopub.execute_input":"2025-06-11T14:21:56.030207Z","iopub.status.idle":"2025-06-11T14:41:26.005009Z","shell.execute_reply.started":"2025-06-11T14:21:56.030178Z","shell.execute_reply":"2025-06-11T14:41:26.002731Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\nfrom sklearn.metrics import make_scorer, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import StackingClassifier\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n# 1) 데이터 로드\nINPUT = '/kaggle/input/open123123121212'\ntrain      = pd.read_csv(f'{INPUT}/train.csv')\ntest       = pd.read_csv(f'{INPUT}/test.csv')\nsubmission = pd.read_csv(f'{INPUT}/sample_submission.csv')\n\n# 2) X, y 준비 및 레이블 인코딩\nX       = train.drop(['ID', 'attack_type'], axis=1)\ny_raw   = train['attack_type']\nle      = LabelEncoder()\ny       = le.fit_transform(y_raw)\n\n# 3) 피처 엔지니어링\ndef port_group(p):\n    if p <= 1023:       return 'well_known'\n    elif p <= 49151:    return 'registered'\n    else:               return 'dynamic'\n\ndef make_features(df):\n    df['port_src_grp'] = df['port_src'].apply(port_group)\n    df['port_dst_grp'] = df['port_dst'].apply(port_group)\n    df['subnet_src'] = (\n        df['ip_src'].fillna('0.0.0.0')\n          .astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['subnet_dst'] = (\n        df['ip_dst'].fillna('0.0.0.0')\n          .astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['pkt_count_total']    = df['pkt_count_fwd'] + df['pkt_count_bwd']\n    df['avg_pkt_size']       = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['pkt_count_total'] + 1e-6)\n    df['byte_ratio_fwd']     = df['rate_fwd_bytes'] / (df['rate_fwd_bytes'] + df['rate_bwd_bytes'] + 1e-6)\n    df['iat_pkt_rate_ratio'] = df['iat_avg_packets'] / (df['rate_fwd_pkts'] + df['rate_bwd_pkts'] + 1e-6)\n    df['tcp_ctrl_ratio']     = (df['tcp_syn_count'] + df['tcp_psh_count'] + df['tcp_rst_count']) / (df['pkt_count_total'] + 1e-6)\n    df['throughput']         = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['duration'] + 1e-6)\n    df['tcp_win_ratio']      = df['tcp_win_fwd_init'] / (df['tcp_win_bwd_init'] + 1e-6)\n    for c in ['duration','pkt_count_fwd','pkt_count_bwd','rate_fwd_pkts','rate_bwd_pkts',\n              'rate_fwd_bytes','rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n              'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']:\n        df[f'{c}_log1p'] = np.log1p(df[c].fillna(0))\n    return df\n\nX    = make_features(X.copy())\ntest = make_features(test.copy())\n\n# 4) 전처리 파이프라인\nnumeric_cols = [\n    'port_src','port_dst','duration','pkt_count_fwd','pkt_count_bwd',\n    'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes','rate_bwd_bytes',\n    'payload_fwd_mean','payload_bwd_mean','tcp_win_fwd_init','tcp_win_bwd_init',\n    'tcp_syn_count','tcp_psh_count','tcp_rst_count','iat_avg_packets',\n    'pkt_count_total','avg_pkt_size','byte_ratio_fwd','iat_pkt_rate_ratio',\n    'tcp_ctrl_ratio','throughput','tcp_win_ratio'\n] + [f'{c}_log1p' for c in ['duration','pkt_count_fwd','pkt_count_bwd',\n                            'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes',\n                            'rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n                            'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']]\ncategorical_features = ['protocol','port_src_grp','port_dst_grp','subnet_src','subnet_dst']\n\nnum_pipe = Pipeline([\n    ('imputer', IterativeImputer(random_state=42, max_iter=10, sample_posterior=True)),\n    ('scaler',  StandardScaler(with_mean=False))\n])\ncat_pipe = Pipeline([\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))\n])\npreproc = ColumnTransformer([\n    ('num', num_pipe, numeric_cols),\n    ('cat', cat_pipe, categorical_features)\n], sparse_threshold=1.0)\n\n# 5) Stacking ensemble (no early stopping inside CV)\nestimators = [\n    ('xgb', XGBClassifier(\n        n_estimators=300, learning_rate=0.05, max_depth=6,\n        subsample=0.8, colsample_bytree=0.8,\n        use_label_encoder=False, eval_metric='mlogloss',\n        random_state=42, n_jobs=4\n    )),\n    ('lgb', LGBMClassifier(\n        n_estimators=300, learning_rate=0.05, num_leaves=50,\n        subsample=0.8, colsample_bytree=0.8,\n        class_weight='balanced',\n        random_state=42, n_jobs=4\n    )),\n    ('cat', CatBoostClassifier(\n        iterations=300, learning_rate=0.05, depth=6,\n        auto_class_weights='Balanced',\n        random_seed=42,\n        verbose=0\n    ))\n]\nstack = StackingClassifier(\n    estimators=estimators,\n    final_estimator=LogisticRegression(max_iter=1000),\n    cv=5,\n    passthrough=True,\n    n_jobs=-1\n)\npipeline = Pipeline([\n    ('pre',   preproc),\n    ('stack', stack)\n])\n\n# 6) Hyperparameter search\nparam_dist = {\n    'stack__xgb__learning_rate': [0.01, 0.05, 0.1],\n    'stack__xgb__max_depth':      [4, 6, 8],\n    'stack__lgb__num_leaves':     [31, 50, 100],\n    'stack__cat__depth':          [4, 6, 8],\n    'stack__final_estimator__C':  [0.01, 0.1, 1, 10],\n}\n\nsearch = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=20,\n    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n    scoring=make_scorer(f1_score, average='macro'),\n    n_jobs=-1,\n    random_state=42,\n    verbose=2\n)\n\n# 7) Fit and tune\nsearch.fit(X, y)\nprint(\"Best CV Macro F1:\", search.best_score_)\nprint(\"Best Params:\", search.best_params_)\n\n# 8) Final predict and save\nbest = search.best_estimator_\npred_int   = best.predict(test)\npred_label = le.inverse_transform(pred_int)\nsubmission['attack_type'] = pred_label\nsubmission.to_csv('/kaggle/working/stacking_tuned_submission.csv', index=False)\nprint(\"Done: /kaggle/working/stacking_tuned_submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T15:15:20.163772Z","iopub.execute_input":"2025-06-11T15:15:20.164613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\nfrom sklearn.metrics import make_scorer, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import StackingClassifier\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n# 1) 데이터 로드\nINPUT = '/kaggle/input/open123123121212'\ntrain      = pd.read_csv(f'{INPUT}/train.csv')\ntest       = pd.read_csv(f'{INPUT}/test.csv')\nsubmission = pd.read_csv(f'{INPUT}/sample_submission.csv')\n\n# 2) X, y 준비 및 레이블 인코딩\nX       = train.drop(['ID', 'attack_type'], axis=1)\ny_raw   = train['attack_type']\nle      = LabelEncoder()\ny       = le.fit_transform(y_raw)\n\n# 3) 피처 엔지니어링\ndef port_group(p):\n    if p <= 1023:       return 'well_known'\n    elif p <= 49151:    return 'registered'\n    else:               return 'dynamic'\n\ndef make_features(df):\n    df['port_src_grp'] = df['port_src'].apply(port_group)\n    df['port_dst_grp'] = df['port_dst'].apply(port_group)\n    df['subnet_src'] = (\n        df['ip_src'].fillna('0.0.0.0')\n          .astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['subnet_dst'] = (\n        df['ip_dst'].fillna('0.0.0.0')\n          .astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['pkt_count_total']    = df['pkt_count_fwd'] + df['pkt_count_bwd']\n    df['avg_pkt_size']       = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['pkt_count_total'] + 1e-6)\n    df['byte_ratio_fwd']     = df['rate_fwd_bytes'] / (df['rate_fwd_bytes'] + df['rate_bwd_bytes'] + 1e-6)\n    df['iat_pkt_rate_ratio'] = df['iat_avg_packets'] / (df['rate_fwd_pkts'] + df['rate_bwd_pkts'] + 1e-6)\n    df['tcp_ctrl_ratio']     = (df['tcp_syn_count'] + df['tcp_psh_count'] + df['tcp_rst_count']) / (df['pkt_count_total'] + 1e-6)\n    df['throughput']         = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['duration'] + 1e-6)\n    df['tcp_win_ratio']      = df['tcp_win_fwd_init'] / (df['tcp_win_bwd_init'] + 1e-6)\n    for c in ['duration','pkt_count_fwd','pkt_count_bwd','rate_fwd_pkts','rate_bwd_pkts',\n              'rate_fwd_bytes','rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n              'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']:\n        df[f'{c}_log1p'] = np.log1p(df[c].fillna(0))\n    return df\n\nX    = make_features(X.copy())\ntest = make_features(test.copy())\n\n# 4) 전처리 파이프라인\nnumeric_cols = [\n    'port_src','port_dst','duration','pkt_count_fwd','pkt_count_bwd',\n    'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes','rate_bwd_bytes',\n    'payload_fwd_mean','payload_bwd_mean','tcp_win_fwd_init','tcp_win_bwd_init',\n    'tcp_syn_count','tcp_psh_count','tcp_rst_count','iat_avg_packets',\n    'pkt_count_total','avg_pkt_size','byte_ratio_fwd','iat_pkt_rate_ratio',\n    'tcp_ctrl_ratio','throughput','tcp_win_ratio'\n] + [f'{c}_log1p' for c in ['duration','pkt_count_fwd','pkt_count_bwd',\n                            'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes',\n                            'rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n                            'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']]\ncategorical_features = ['protocol','port_src_grp','port_dst_grp','subnet_src','subnet_dst']\n\nnum_pipe = Pipeline([\n    ('imputer', IterativeImputer(random_state=42, max_iter=10, sample_posterior=True)),\n    ('scaler',  StandardScaler(with_mean=False))\n])\ncat_pipe = Pipeline([\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))\n])\npreproc = ColumnTransformer([\n    ('num', num_pipe, numeric_cols),\n    ('cat', cat_pipe, categorical_features)\n], sparse_threshold=1.0)\n\n# 5) Stacking ensemble (no early stopping inside CV)\nestimators = [\n    ('xgb', XGBClassifier(\n        n_estimators=300, learning_rate=0.05, max_depth=6,\n        subsample=0.8, colsample_bytree=0.8,\n        use_label_encoder=False, eval_metric='mlogloss',\n        random_state=42, n_jobs=4\n    )),\n    ('lgb', LGBMClassifier(\n        n_estimators=300, learning_rate=0.05, num_leaves=50,\n        subsample=0.8, colsample_bytree=0.8,\n        class_weight='balanced',\n        random_state=42, n_jobs=4\n    )),\n    ('cat', CatBoostClassifier(\n        iterations=300, learning_rate=0.05, depth=6,\n        auto_class_weights='Balanced',\n        random_seed=42,\n        verbose=0\n    ))\n]\nstack = StackingClassifier(\n    estimators=estimators,\n    final_estimator=LogisticRegression(max_iter=1000),\n    cv=5,\n    passthrough=True,\n    n_jobs=-1\n)\npipeline = Pipeline([\n    ('pre',   preproc),\n    ('stack', stack)\n])\n\n# 6) Hyperparameter search\nparam_dist = {\n    'stack__xgb__learning_rate': [0.01, 0.05, 0.1],\n    'stack__xgb__max_depth':      [4, 6, 8],\n    'stack__lgb__num_leaves':     [31, 50, 100],\n    'stack__cat__depth':          [4, 6, 8],\n    'stack__final_estimator__C':  [0.01, 0.1, 1, 10],\n}\n\nsearch = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=20,\n    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n    scoring=make_scorer(f1_score, average='macro'),\n    n_jobs=-1,\n    random_state=42,\n    verbose=2\n)\n\n# 7) Fit and tune\nsearch.fit(X, y)\nprint(\"Best CV Macro F1:\", search.best_score_)\nprint(\"Best Params:\", search.best_params_)\n\n# 8) Final predict and save\nbest = search.best_estimator_\npred_int   = best.predict(test)\npred_label = le.inverse_transform(pred_int)\nsubmission['attack_type'] = pred_label\nsubmission.to_csv('/kaggle/working/stacking_tuned_submission.csv', index=False)\nprint(\"Done: /kaggle/working/stacking_tuned_submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T18:23:12.354536Z","iopub.execute_input":"2025-06-11T18:23:12.354885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\nfrom sklearn.metrics import make_scorer, f1_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import StackingClassifier\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\n\n# 1) 데이터 로드\nINPUT = '/kaggle/input/open123123121212'\ntrain      = pd.read_csv(f'{INPUT}/train.csv')\ntest       = pd.read_csv(f'{INPUT}/test.csv')\nsubmission = pd.read_csv(f'{INPUT}/sample_submission.csv')\n\n# 2) X, y 준비 및 레이블 인코딩\nX       = train.drop(['ID','attack_type'], axis=1)\ny_raw   = train['attack_type']\nle      = LabelEncoder()\ny       = le.fit_transform(y_raw)\n\n# 3) 피처 엔지니어링\ndef port_group(p):\n    if p <= 1023:       return 'well_known'\n    elif p <= 49151:    return 'registered'\n    else:               return 'dynamic'\n\ndef make_features(df):\n    df['port_src_grp'] = df['port_src'].apply(port_group)\n    df['port_dst_grp'] = df['port_dst'].apply(port_group)\n    df['subnet_src'] = (\n        df['ip_src'].fillna('0.0.0.0')\n          .astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['subnet_dst'] = (\n        df['ip_dst'].fillna('0.0.0.0')\n          .astype(str)\n          .str.split(pat='.', n=3).str[:2].str.join('.')\n    )\n    df['pkt_count_total']    = df['pkt_count_fwd'] + df['pkt_count_bwd']\n    df['avg_pkt_size']       = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['pkt_count_total'] + 1e-6)\n    df['byte_ratio_fwd']     = df['rate_fwd_bytes'] / (df['rate_fwd_bytes'] + df['rate_bwd_bytes'] + 1e-6)\n    df['iat_pkt_rate_ratio'] = df['iat_avg_packets'] / (df['rate_fwd_pkts'] + df['rate_bwd_pkts'] + 1e-6)\n    df['tcp_ctrl_ratio']     = (df['tcp_syn_count'] + df['tcp_psh_count'] + df['tcp_rst_count']) / (df['pkt_count_total'] + 1e-6)\n    df['throughput']         = (df['rate_fwd_bytes'] + df['rate_bwd_bytes']) / (df['duration'] + 1e-6)\n    df['tcp_win_ratio']      = df['tcp_win_fwd_init'] / (df['tcp_win_bwd_init'] + 1e-6)\n    # log1p 변환\n    for c in ['duration','pkt_count_fwd','pkt_count_bwd','rate_fwd_pkts','rate_bwd_pkts',\n              'rate_fwd_bytes','rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n              'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']:\n        df[f'{c}_log1p'] = np.log1p(df[c].fillna(0))\n    return df\n\nX    = make_features(X.copy())\ntest = make_features(test.copy())\n\n# 4) 전처리 파이프라인\nnumeric_cols = [\n    'port_src','port_dst','duration','pkt_count_fwd','pkt_count_bwd',\n    'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes','rate_bwd_bytes',\n    'payload_fwd_mean','payload_bwd_mean','tcp_win_fwd_init','tcp_win_bwd_init',\n    'tcp_syn_count','tcp_psh_count','tcp_rst_count','iat_avg_packets',\n    'pkt_count_total','avg_pkt_size','byte_ratio_fwd','iat_pkt_rate_ratio',\n    'tcp_ctrl_ratio','throughput','tcp_win_ratio'\n] + [f'{c}_log1p' for c in ['duration','pkt_count_fwd','pkt_count_bwd',\n                            'rate_fwd_pkts','rate_bwd_pkts','rate_fwd_bytes',\n                            'rate_bwd_bytes','payload_fwd_mean','payload_bwd_mean',\n                            'tcp_win_fwd_init','tcp_win_bwd_init','iat_avg_packets']]\ncategorical_features = ['protocol','port_src_grp','port_dst_grp','subnet_src','subnet_dst']\n\nnum_pipe = Pipeline([\n    ('imputer', IterativeImputer(random_state=42)),\n    ('scaler',  StandardScaler(with_mean=False))\n])\ncat_pipe = Pipeline([\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=True))\n])\npreproc = ColumnTransformer([\n    ('num', num_pipe, numeric_cols),\n    ('cat', cat_pipe, categorical_features)\n], sparse_threshold=1.0)\n\n# 5) Stacking ensemble\nestimators = [\n    ('xgb', XGBClassifier(\n        n_estimators=300, learning_rate=0.05, max_depth=6,\n        subsample=0.8, colsample_bytree=0.8,\n        use_label_encoder=False, eval_metric='mlogloss',\n        random_state=42, n_jobs=4\n    )),\n    ('lgb', LGBMClassifier(\n        n_estimators=300, learning_rate=0.05, num_leaves=50,\n        subsample=0.8, colsample_bytree=0.8,\n        class_weight='balanced',\n        random_state=42, n_jobs=4\n    )),\n    ('cat', CatBoostClassifier(\n        iterations=300, learning_rate=0.05, depth=6,\n        auto_class_weights='Balanced',\n        random_seed=42,\n        verbose=0\n    ))\n]\nstack = StackingClassifier(\n    estimators=estimators,\n    final_estimator=LogisticRegression(max_iter=1000),\n    cv=5,\n    passthrough=True,\n    n_jobs=-1\n)\npipeline = Pipeline([\n    ('pre',   preproc),\n    ('stack', stack)\n])\n\n# 6) Hyperparameter search\nparam_dist = {\n    'stack__xgb__learning_rate': [0.01, 0.05, 0.1],\n    'stack__xgb__max_depth':      [4,  6,  8],\n    'stack__lgb__num_leaves':     [31, 50, 100],\n    'stack__cat__depth':          [4,  6,  8],\n    'stack__final_estimator__C':  [0.01, 0.1, 1, 10],\n}\nsearch = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=20,\n    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n    scoring=make_scorer(f1_score, average='macro'),\n    n_jobs=-1,\n    random_state=42,\n    verbose=2\n)\n\n# 7) Fit & tune\nsearch.fit(X, y)\nprint(\"Best CV Macro F1:\", search.best_score_)\nprint(\"Best Params:\", search.best_params_)\n\n# 8) 예측 및 제출 파일 저장\nbest = search.best_estimator_\npred_int   = best.predict(test)\npred_label = le.inverse_transform(pred_int)\nsubmission['attack_type'] = pred_label\nsubmission.to_csv('/kaggle/working/stacking_tuned_submission.csv', index=False)\nprint(\"Saved to /kaggle/working/stacking_tuned_submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T00:01:53.691692Z","iopub.execute_input":"2025-06-12T00:01:53.692012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.experimental import enable_iterative_imputer  # noqa\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\nfrom sklearn.metrics import make_scorer, f1_score\nfrom sklearn.ensemble import VotingClassifier\n\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n# 1) 데이터 로드\nINPUT = '/kaggle/input/open123123121212'\ntrain      = pd.read_csv(f'{INPUT}/train.csv')\ntest       = pd.read_csv(f'{INPUT}/test.csv')\nsubmission = pd.read_csv(f'{INPUT}/sample_submission.csv')\n\n# 2) X, y 준비 및 레이블 인코딩\nX       = train.drop(['ID','attack_type'], axis=1)\ny_raw   = train['attack_type']\nle      = LabelEncoder()\ny       = le.fit_transform(y_raw)\n\n# 3) 파생 변수 + 전처리 (위와 동일)\ndef port_group(p):\n    if p <= 1023:       return 'well_known'\n    elif p <= 49151:    return 'registered'\n    else:               return 'dynamic'\n\ndef make_features(df):\n    df['port_src_grp'] = df['port_src'].apply(port_group)\n    df['port_dst_grp'] = df['port_dst'].apply(port_group)\n    df['subnet_src'] = df['ip_src'].fillna('0.0.0.0').astype(str).str.split('.',3).str[:2].str.join('.')\n    df['subnet_dst'] = df['ip_dst'].fillna('0.0.0.0').astype(str).str.split('.',3).str[:2].str.join('.')\n    df['pkt_count_total']    = df['pkt_count_fwd'] + df['pkt_count_bwd']\n    df['avg_pkt_size']       = (df['rate_fwd_bytes'] + df['rate_bwd_bytes'])/(df['pkt_count_total']+1e-6)\n    df['byte_ratio_fwd']     = df['rate_fwd_bytes']/(df['rate_fwd_bytes']+df['rate_bwd_bytes']+1e-6)\n    df['throughput']         = (df['rate_fwd_bytes']+df['rate_bwd_bytes'])/(df['duration']+1e-6)\n    for c in ['duration','pkt_count_fwd','pkt_count_bwd','rate_fwd_pkts','rate_bwd_pkts',\n              'rate_fwd_bytes','rate_bwd_bytes']:\n        df[f'{c}_log1p'] = np.log1p(df[c].fillna(0))\n    return df\n\nX    = make_features(X.copy())\ntest = make_features(test.copy())\n\n# numeric / categorical lists (로그 컬럼 포함)\nnumeric_cols = [c for c in X.columns if c not in ['ID','attack_type','protocol','ip_src','ip_dst']]\ncategorical = ['protocol','port_src_grp','port_dst_grp','subnet_src','subnet_dst']\n\npreproc = ColumnTransformer([\n    ('num', Pipeline([\n        ('imp',   IterativeImputer(random_state=42)),\n        ('scale', StandardScaler(with_mean=False))\n    ]), numeric_cols),\n    ('cat', OneHotEncoder(handle_unknown='ignore', sparse=True), categorical)\n], sparse_threshold=1.0)\n\n# 4) 모델 정의\nxgb = XGBClassifier(\n    n_estimators=200,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    use_label_encoder=False,\n    eval_metric='mlogloss',\n    random_state=42,\n    n_jobs=4\n)\nlgb = LGBMClassifier(\n    n_estimators=200,\n    learning_rate=0.05,\n    num_leaves=50,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    class_weight='balanced',\n    random_state=42,\n    n_jobs=4\n)\n\nvoting = VotingClassifier(\n    estimators=[('xgb', xgb), ('lgb', lgb)],\n    voting='soft',\n    weights=[1,1],\n    n_jobs=-1\n)\n\npipeline = Pipeline([\n    ('pre', preproc),\n    ('clf', voting)\n])\n\n# 5) Hyperparameter search (5 iters × 3-fold)\nparam_dist = {\n    'clf__xgb__learning_rate': [0.01, 0.05, 0.1],\n    'clf__xgb__max_depth':      [4, 6, 8],\n    'clf__lgb__num_leaves':     [31, 50, 100]\n}\n\nsearch = RandomizedSearchCV(\n    pipeline,\n    param_distributions=param_dist,\n    n_iter=5,\n    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n    scoring=make_scorer(f1_score, average='macro'),\n    n_jobs=-1,\n    random_state=42,\n    verbose=2\n)\nsearch.fit(X, y)\nprint(\"Lite CV Macro F1:\", search.best_score_)\nprint(\"Best Params:\", search.best_params_)\n\n# 6) 최종 예측 & 저장\nbest = search.best_estimator_\npred_int   = best.predict(test)\npred_label = le.inverse_transform(pred_int)\nsubmission['attack_type'] = pred_label\nsubmission.to_csv('/kaggle/working/lite_ensemble_submission.csv', index=False)\nprint(\"Saved:\", '/kaggle/working/lite_ensemble_submission.csv')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}